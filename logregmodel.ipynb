{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c488d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import dump, load\n",
    "import ast\n",
    "\n",
    "# set of stopwords from NLTK \n",
    "stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e93c2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    sentence_list = []\n",
    "    for word in text.lower().split():\n",
    "        if word not in stops:\n",
    "\n",
    "            word_list = []\n",
    "            for char in word:\n",
    "                if char.isalpha():\n",
    "                    word_list.append(char)\n",
    "            if len(word_list) != 0:\n",
    "                sentence_list.append(''.join(word_list))\n",
    "    return ' '.join(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1236c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test\n",
    "assert preprocess(\"A true random number generator (TRNG), also known as a hardware random number generator (HRNG), does not use a computer algorithm. Instead, it uses an external unpredictable physical variable such as radioactive decay of isotopes or airwave static to generate random numbers.\") == 'true random number generator trng also known hardware random number generator hrng use computer algorithm instead uses external unpredictable physical variable radioactive decay isotopes airwave static generate random numbers'\n",
    "assert preprocess(\"This IS A test !!!! I hope this makes SENSE\") == 'test hope makes sense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23267c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Needham analyst Laura Martin reiterated Amazon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The analyst raised her fiscal 2024 profit esti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She also expects fiscal 2023’s cost-cutting ac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Also Read: Amazon Aims to Outdo Walmart’s Reta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For the first quarter of 2024, Martin maintain...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28251</th>\n",
       "      <td>Moreover, Apple has struggled with product div...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28252</th>\n",
       "      <td>Apple looks like a front-runner among tech sto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28253</th>\n",
       "      <td>On the date of publication, Tyrik Torres did n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28254</th>\n",
       "      <td>Tyrik Torres has been studying and participati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28255</th>\n",
       "      <td>The post 3 Tech Stocks to Sell in March Before...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paragraph  relevant\n",
       "0      Needham analyst Laura Martin reiterated Amazon...         1\n",
       "1      The analyst raised her fiscal 2024 profit esti...         1\n",
       "2      She also expects fiscal 2023’s cost-cutting ac...         1\n",
       "3      Also Read: Amazon Aims to Outdo Walmart’s Reta...         1\n",
       "4      For the first quarter of 2024, Martin maintain...         1\n",
       "...                                                  ...       ...\n",
       "28251  Moreover, Apple has struggled with product div...         1\n",
       "28252  Apple looks like a front-runner among tech sto...         1\n",
       "28253  On the date of publication, Tyrik Torres did n...         0\n",
       "28254  Tyrik Torres has been studying and participati...         0\n",
       "28255  The post 3 Tech Stocks to Sell in March Before...         0\n",
       "\n",
       "[28256 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('paragraph.csv')\n",
    "\n",
    "# drop irrelevant columns and nulls\n",
    "df = df1.drop(columns=['Unnamed: 0', 'ticker', 'link'])\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# apply preprocessing and create boolean columns with numerical val \n",
    "df['relevant'] = df['relevant'].apply(lambda x: 1 if x == True else 0)\n",
    "# df['paragraph'] = df['paragraph'].apply(lambda x: preprocess(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6553d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rachel/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "500 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Rachel/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/Rachel/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/Rachel/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/Rachel/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/Rachel/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.78864412        nan 0.78973007        nan 0.79019547\n",
      "        nan 0.79047471        nan 0.79515979        nan 0.7957493\n",
      "        nan 0.80452994        nan 0.81020788        nan 0.83028235\n",
      "        nan 0.85144276        nan 0.87533354        nan 0.88175613\n",
      "        nan 0.88442445        nan 0.89457028        nan 0.90859448\n",
      "        nan 0.91659944        nan 0.92081911        nan 0.92947564\n",
      "        nan 0.93834936        nan 0.94778157        nan 0.95594167\n",
      "        nan 0.96202296        nan 0.96822836        nan 0.97393733\n",
      "        nan 0.97825008        nan 0.98240769        nan 0.98591374\n",
      "        nan 0.98889234        nan 0.99140552        nan 0.99221222\n",
      "        nan 0.9934533         nan 0.99422898        nan 0.99481849\n",
      "        nan 0.99444617        nan 0.99472541        nan 0.99481849\n",
      "        nan 0.99472541        nan 0.99373255        nan 0.99475644\n",
      "        nan 0.99444617        nan 0.99466336        nan 0.99432206\n",
      "        nan 0.99435309        nan 0.99469438        nan 0.99398076\n",
      "        nan 0.9937946         nan 0.99363947        nan 0.99342228\n",
      "        nan 0.99342228        nan 0.99348433]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X = vectorizer.fit_transform(df.paragraph)\n",
    "y = df.relevant\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 50),  # Regularization strength\n",
    "    'penalty': ['l1', 'l2']  # Types of regularization\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit model on training data\n",
    "model = grid_search.fit(X_train_smote, y_train_smote);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65837975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3664 16115]\n",
      "[16115 16115]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a463d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1587\n",
      "           1       0.99      0.99      0.99      6890\n",
      "\n",
      "    accuracy                           0.99      8477\n",
      "   macro avg       0.98      0.98      0.98      8477\n",
      "weighted avg       0.99      0.99      0.99      8477\n",
      "\n",
      "Accuracy Score: 0.9871416774802406\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174bab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_logreg(model, lst, vectorizer):\n",
    "\n",
    "    preprocessed_list = [preprocess(para) for para in lst]\n",
    "    \n",
    "    # Transform all preprocessed paragraphs using the already fitted vectorizer\n",
    "    X = vectorizer.transform(preprocessed_list)\n",
    "\n",
    "    # Predict using the logistic regression model\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Append paragraphs where the prediction is 0\n",
    "    new = [para for idx, para in enumerate(lst) if y_pred[idx] != 0]\n",
    "    \n",
    "    # Return the combined text of the filtered paragraphs\n",
    "    return ' '.join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3947cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit tests for verify_logreg\n",
    "preprocLst1 = [\"hello want\", \"hello kitty\", \"talk about real life\"]\n",
    "assert verify_logreg(model, preprocLst1, vectorizer) == 'hello want talk about real life'\n",
    "preprocLst2 = [\"world burn alive hot\", \"environmental change\"]\n",
    "assert verify_logreg(model, preprocLst2, vectorizer) == 'world burn alive hot environmental change'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5268fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('stockNews.csv')\n",
    "df_final['paragraphList'] = df_final['paragraphList'].apply(lambda x: ast.literal_eval(x))\n",
    "df_final['articleInfo'] = df_final['paragraphList'].apply(lambda x: verify_logreg(model, x, vectorizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6996022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('FinalStockNews.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
