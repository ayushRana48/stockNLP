{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d6e72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from nltk.corpus import stopwords\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65473af7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSequenceClassification, AutoTokenizer\n\u001b[1;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProsusAI/finbert\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1070\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1070\u001b[0m requires_backends(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_backends)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/import_utils.py:1049\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[0;32m-> 1049\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[0;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e4a61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>articleInfo</th>\n",
       "      <th>paragraphList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Tech Layoffs, Remote Work Push Office Vacancie...</td>\n",
       "      <td>2024-04-16T00:00:00</td>\n",
       "      <td>/news/etf/tech-layoffs-remote-work-push-office...</td>\n",
       "      <td>The commercial real estate industry continues ...</td>\n",
       "      <td>['The commercial real estate industry continue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>The 3 Best Stocks to Buy With Your Tax Refund ...</td>\n",
       "      <td>2024-04-16T00:00:00</td>\n",
       "      <td>/news/stocks/the-3-best-stocks-to-buy-with-you...</td>\n",
       "      <td>The IRS typically gives tax refunds within 21 ...</td>\n",
       "      <td>['InvestorPlace - Stock Market News, Stock Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3 AI Stocks to Buy Now: Q2 Edition</td>\n",
       "      <td>2024-04-16T00:00:00</td>\n",
       "      <td>/news/stocks/3-ai-stocks-to-buy-now-q2-edition...</td>\n",
       "      <td>Just like electricity and the internet unleash...</td>\n",
       "      <td>['InvestorPlace - Stock Market News, Stock Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon, Meta, Uber Remain 'Top Overall Picks' ...</td>\n",
       "      <td>2024-04-16T00:00:00</td>\n",
       "      <td>/news/stocks/amazon-meta-uber-remain-top-overa...</td>\n",
       "      <td>As the first-quarter (Q1) 2024 earnings season...</td>\n",
       "      <td>['As the first-quarter (Q1) 2024 earnings seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon (AMZN) Receives a Buy from J.P. Morgan</td>\n",
       "      <td>2024-04-16T00:00:00</td>\n",
       "      <td>/news/stocks/amazon-amzn-receives-a-buy-from-j...</td>\n",
       "      <td>J.P. Morgan analyst Doug Anmuth maintained a B...</td>\n",
       "      <td>['J.P. Morgan analyst Doug Anmuth maintained a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>1559</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Riding the Bull: 3 ETFs to Capitalize on the O...</td>\n",
       "      <td>2024-03-13T00:00:00</td>\n",
       "      <td>/news/stocks/riding-the-bull-3-etfs-to-capital...</td>\n",
       "      <td>There are many advantages to owing exchange-tr...</td>\n",
       "      <td>['InvestorPlace - Stock Market News, Stock Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1560</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple’s Bitter Bite: Is the Tech Giant’s Slowi...</td>\n",
       "      <td>2024-03-13T00:00:00</td>\n",
       "      <td>/news/stocks/apples-bitter-bite-is-the-tech-gi...</td>\n",
       "      <td>The market has shown extreme volatility for mo...</td>\n",
       "      <td>['InvestorPlace - Stock Market News, Stock Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>1561</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>SCHD ETF Spotlight: The Top 6 Stocks Inside Th...</td>\n",
       "      <td>2024-03-13T00:00:00</td>\n",
       "      <td>/news/stocks/schd-etf-spotlight-the-top-6-stoc...</td>\n",
       "      <td>Investing in the stock market is one of the su...</td>\n",
       "      <td>['InvestorPlace - Stock Market News, Stock Adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>1562</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Maintaining Market-Perform on Apple: A Balance...</td>\n",
       "      <td>2024-03-13T00:00:00</td>\n",
       "      <td>/news/stocks/maintaining-market-perform-on-app...</td>\n",
       "      <td>Bernstein analyst Toni Sacconaghi maintained a...</td>\n",
       "      <td>['Bernstein analyst Toni Sacconaghi maintained...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>1563</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Allows EU Users To Download Apps Directl...</td>\n",
       "      <td>2024-03-12T00:00:00</td>\n",
       "      <td>/news/stocks/apple-allows-eu-users-to-download...</td>\n",
       "      <td>(RTTNews) - Apple Inc. (AAPL) has announced th...</td>\n",
       "      <td>[\"(RTTNews) - Apple Inc. (AAPL) has announced ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1564 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1 ticker                                              title  \\\n",
       "0                0   AMZN  Tech Layoffs, Remote Work Push Office Vacancie...   \n",
       "1                1   AMZN  The 3 Best Stocks to Buy With Your Tax Refund ...   \n",
       "2                2   AMZN                 3 AI Stocks to Buy Now: Q2 Edition   \n",
       "3                3   AMZN  Amazon, Meta, Uber Remain 'Top Overall Picks' ...   \n",
       "4                4   AMZN      Amazon (AMZN) Receives a Buy from J.P. Morgan   \n",
       "...            ...    ...                                                ...   \n",
       "1559          1559   AAPL  Riding the Bull: 3 ETFs to Capitalize on the O...   \n",
       "1560          1560   AAPL  Apple’s Bitter Bite: Is the Tech Giant’s Slowi...   \n",
       "1561          1561   AAPL  SCHD ETF Spotlight: The Top 6 Stocks Inside Th...   \n",
       "1562          1562   AAPL  Maintaining Market-Perform on Apple: A Balance...   \n",
       "1563          1563   AAPL  Apple Allows EU Users To Download Apps Directl...   \n",
       "\n",
       "                     date                                               link  \\\n",
       "0     2024-04-16T00:00:00  /news/etf/tech-layoffs-remote-work-push-office...   \n",
       "1     2024-04-16T00:00:00  /news/stocks/the-3-best-stocks-to-buy-with-you...   \n",
       "2     2024-04-16T00:00:00  /news/stocks/3-ai-stocks-to-buy-now-q2-edition...   \n",
       "3     2024-04-16T00:00:00  /news/stocks/amazon-meta-uber-remain-top-overa...   \n",
       "4     2024-04-16T00:00:00  /news/stocks/amazon-amzn-receives-a-buy-from-j...   \n",
       "...                   ...                                                ...   \n",
       "1559  2024-03-13T00:00:00  /news/stocks/riding-the-bull-3-etfs-to-capital...   \n",
       "1560  2024-03-13T00:00:00  /news/stocks/apples-bitter-bite-is-the-tech-gi...   \n",
       "1561  2024-03-13T00:00:00  /news/stocks/schd-etf-spotlight-the-top-6-stoc...   \n",
       "1562  2024-03-13T00:00:00  /news/stocks/maintaining-market-perform-on-app...   \n",
       "1563  2024-03-12T00:00:00  /news/stocks/apple-allows-eu-users-to-download...   \n",
       "\n",
       "                                            articleInfo  \\\n",
       "0     The commercial real estate industry continues ...   \n",
       "1     The IRS typically gives tax refunds within 21 ...   \n",
       "2     Just like electricity and the internet unleash...   \n",
       "3     As the first-quarter (Q1) 2024 earnings season...   \n",
       "4     J.P. Morgan analyst Doug Anmuth maintained a B...   \n",
       "...                                                 ...   \n",
       "1559  There are many advantages to owing exchange-tr...   \n",
       "1560  The market has shown extreme volatility for mo...   \n",
       "1561  Investing in the stock market is one of the su...   \n",
       "1562  Bernstein analyst Toni Sacconaghi maintained a...   \n",
       "1563  (RTTNews) - Apple Inc. (AAPL) has announced th...   \n",
       "\n",
       "                                          paragraphList  \n",
       "0     ['The commercial real estate industry continue...  \n",
       "1     ['InvestorPlace - Stock Market News, Stock Adv...  \n",
       "2     ['InvestorPlace - Stock Market News, Stock Adv...  \n",
       "3     ['As the first-quarter (Q1) 2024 earnings seas...  \n",
       "4     ['J.P. Morgan analyst Doug Anmuth maintained a...  \n",
       "...                                                 ...  \n",
       "1559  ['InvestorPlace - Stock Market News, Stock Adv...  \n",
       "1560  ['InvestorPlace - Stock Market News, Stock Adv...  \n",
       "1561  ['InvestorPlace - Stock Market News, Stock Adv...  \n",
       "1562  ['Bernstein analyst Toni Sacconaghi maintained...  \n",
       "1563  [\"(RTTNews) - Apple Inc. (AAPL) has announced ...  \n",
       "\n",
       "[1564 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('FinalStockNews.csv')\n",
    "for col in df.columns:\n",
    "    col = col.strip\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51407d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDfStock(ticker, startDate, endDate):\n",
    "    # Convert startDate and endDate to datetime objects to ensure proper comparison\n",
    "    start_date = pd.to_datetime(startDate)\n",
    "    end_date = pd.to_datetime(endDate)\n",
    "\n",
    "    # Ensure the 'date' column is in datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Filter the DataFrame for the given ticker and the date range inclusive\n",
    "    filtered_df = df[(df['ticker'] == ticker) & (df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "\n",
    "    return filtered_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730acaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(text, tokenizer, max_length=512, overlap=50):\n",
    "\n",
    "    #encodes text\n",
    "    tokenized_text = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=True)\n",
    "    input_ids = tokenized_text['input_ids'].squeeze().numpy().tolist()\n",
    "    \n",
    "    total_length = len(input_ids)\n",
    "    #each step is 462 by default\n",
    "    step_size = max_length - overlap\n",
    "    chunks = []\n",
    "    \n",
    "    #create sliding window and tokenize each chunk\n",
    "    for start in range(0, total_length, step_size):\n",
    "        end = start + max_length\n",
    "        chunk = input_ids[start:end]\n",
    "        \n",
    "        chunk = [tokenizer.cls_token_id] + chunk + [tokenizer.sep_token_id]\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e7bacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunks(chunks, tokenizer, model):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()  \n",
    "    \n",
    "    # Lists to store sentiments and scores\n",
    "    sentiments = []\n",
    "    scores = []\n",
    "    \n",
    "    # Disable gradient calculation for efficiency\n",
    "    with torch.no_grad():\n",
    "        # Iterate through each chunk\n",
    "        for chunk in chunks:\n",
    "            # Convert the chunk into a PyTorch tensor and add a batch dimension\n",
    "            inputs = torch.tensor(chunk).unsqueeze(0)  \n",
    "            \n",
    "            # Pad the input tensor to match the model's input size\n",
    "            inputs = torch.nn.functional.pad(inputs, (0, 512 - inputs.shape[1]), value=tokenizer.pad_token_id)\n",
    "            # Pass the input tensor through the model\n",
    "            outputs = model(inputs)\n",
    "            # Retrieve the logits (raw outputs) from the model\n",
    "            logits = outputs.logits\n",
    "            # Determine the sentiment by selecting the index of the maximum logit value\n",
    "            sentiment = torch.argmax(logits, dim=1).numpy()[0]  \n",
    "            # Calculate the softmax probability score for the predicted sentiment\n",
    "            score = torch.softmax(logits, dim=1).max().item()  \n",
    "            # Append the sentiment and score to their respective lists\n",
    "            sentiments.append(sentiment)\n",
    "            scores.append(score)\n",
    "\n",
    "    # Return the lists of sentiments and scores\n",
    "    return sentiments, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e130527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results(sentiments, scores):\n",
    "    # Dictionary to store average score per sentiment\n",
    "    average_score_per_sentiment = {}\n",
    "    # Iterate through each sentiment and score pair\n",
    "    for sentiment, score in zip(sentiments, scores):\n",
    "        # If sentiment not in the dictionary, add it with an empty list\n",
    "        if sentiment not in average_score_per_sentiment:\n",
    "            average_score_per_sentiment[sentiment] = []\n",
    "        # Append the score to the list of scores for this sentiment\n",
    "        average_score_per_sentiment[sentiment].append(score)\n",
    "    \n",
    "    # Calculate the average score for each sentiment\n",
    "    for sentiment in average_score_per_sentiment:\n",
    "        average_score_per_sentiment[sentiment] = sum(average_score_per_sentiment[sentiment]) / len(average_score_per_sentiment[sentiment])\n",
    "    \n",
    "    # Find the dominant sentiment (the one with the highest average score)\n",
    "    dominant_sentiment = max(average_score_per_sentiment, key=average_score_per_sentiment.get)\n",
    "    \n",
    "    # Return the dominant sentiment and its average score\n",
    "    return dominant_sentiment, average_score_per_sentiment[dominant_sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29f1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_window(text, tokenizer, model):\n",
    "    # Generate chunks of text using a sliding window approach\n",
    "    chunks = sliding_window(text, tokenizer)\n",
    "    # Process the chunks to obtain sentiments and scores\n",
    "    sentiments, scores = process_chunks(chunks, tokenizer, model)\n",
    "    # Aggregate the results to find the dominant sentiment and its average score\n",
    "    return aggregate_results(sentiments, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a8a68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentimentScore(ticker, startDate, endDate):\n",
    "    # Retrieve the subset DataFrame for the specified ticker and date range\n",
    "    subDf = getDfStock(ticker, startDate, endDate)\n",
    "\n",
    "    # Assume the function `full_window` applies sentiment analysis and returns the sentiment as 'positive', 'negative', or 'neutral'\n",
    "    subDf['sentiment'] = subDf['articleInfo'].apply(lambda articleInfo: full_window(articleInfo, tokenizer, model)[0])\n",
    "\n",
    "    # Map the sentiment results to numeric values: positive -> 1, neutral -> 0.5, negative -> 0\n",
    "    sentiment_scores = subDf['sentiment'].map({'positive': 1, 'neutral': 0.5, 'negative': 0})\n",
    "\n",
    "    # Calculate the average sentiment score\n",
    "    if len(sentiment_scores) > 0:\n",
    "        average_sentiment_score = sentiment_scores.mean()\n",
    "    else:\n",
    "        average_sentiment_score = None  # Handle case where no articles were found\n",
    "\n",
    "    return average_sentiment_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
